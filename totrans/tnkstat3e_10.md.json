["```py\nfrom  os.path  import basename, exists\n\ndef  download(url):\n    filename = basename(url)\n    if not exists(filename):\n        from  urllib.request  import urlretrieve\n\n        local, _ = urlretrieve(url, filename)\n        print(\"Downloaded \" + local)\n\ndownload(\"https://github.com/AllenDowney/ThinkStats/raw/v3/nb/thinkstats.py\") \n```", "```py\ntry:\n    import  empiricaldist\nexcept ImportError:\n    %pip install empiricaldist \n```", "```py\nimport  numpy  as  np\nimport  pandas  as  pd\nimport  matplotlib.pyplot  as  plt\n\nfrom  thinkstats  import decorate \n```", "```py\nmu = 3.7\nsigma = 0.46 \n```", "```py\n# Seed the random number generator so we get the same results every time\nnp.random.seed(1) \n```", "```py\nsample = np.random.normal(mu, sigma, size=10)\nsample \n```", "```py\narray([4.44719887, 3.41859205, 3.45704099, 3.20643443, 4.09808751,\n       2.6412922 , 4.50261341, 3.34984483, 3.84675798, 3.58528963]) \n```", "```py\nnp.mean(sample), np.median(sample) \n```", "```py\n(np.float64(3.6553151902291945), np.float64(3.521165310619601)) \n```", "```py\ndef  make_sample(n):\n    return np.random.normal(mu, sigma, size=n) \n```", "```py\nns = np.logspace(1, 5).astype(int) \n```", "```py\nmeans = [np.mean(make_sample(n)) for n in ns] \n```", "```py\nmedians = [np.median(make_sample(n)) for n in ns] \n```", "```py\nplt.axhline(mu, color=\"gray\", lw=1, alpha=0.5)\nplt.plot(ns, means, \"--\", label=\"mean\")\nplt.plot(ns, medians, alpha=0.5, label=\"median\")\n\ndecorate(xlabel=\"Sample size\", xscale=\"log\", ylabel=\"Estimate\") \n```", "```py\nmeans = [np.mean(make_sample(n=10)) for i in range(10001)]\nnp.mean(means) \n```", "```py\nnp.float64(3.70034508492869) \n```", "```py\nmedians = [np.median(make_sample(n=10)) for i in range(10001)]\nnp.mean(medians) \n```", "```py\nnp.float64(3.701214089907223) \n```", "```py\ndef  mse(estimates, actual):\n  \"\"\"Mean squared error of a sequence of estimates.\"\"\"\n    errors = np.asarray(estimates) - actual\n    return np.mean(errors**2) \n```", "```py\nmse(means, mu) \n```", "```py\nnp.float64(0.020871984891289382) \n```", "```py\nmse(medians, mu) \n```", "```py\nnp.float64(0.029022273128644173) \n```", "```py\ndef  mae(estimates, actual):\n  \"\"\"Mean absolute error of a sequence of estimates.\"\"\"\n    errors = np.asarray(estimates) - actual\n    return np.mean(np.abs(errors)) \n```", "```py\nmae(means, mu) \n```", "```py\nnp.float64(0.11540433749505272) \n```", "```py\nmae(medians, mu) \n```", "```py\nnp.float64(0.13654429774596036) \n```", "```py\ndef  make_sample_with_errors(n):\n    sample = np.random.normal(mu, sigma, size=n)\n    factor = np.random.choice([1, 2.2], p=[0.98, 0.02], size=n)\n    return sample * factor \n```", "```py\nsample = make_sample_with_errors(n=1000) \n```", "```py\nfrom  scipy.stats  import gaussian_kde\nfrom  thinkstats  import Pdf\n\nkde = gaussian_kde(sample)\ndomain = 0, 10\npdf = Pdf(kde, domain)\npdf.plot(label='estimated density')\ndecorate(xlabel=\"Penguin weight (kg)\", ylabel=\"Density\") \n```", "```py\nmeans = [np.mean(make_sample_with_errors(n=10)) for i in range(10001)]\nnp.mean(means) \n```", "```py\nnp.float64(3.786352945690677) \n```", "```py\nmedians = [np.median(make_sample_with_errors(n=10)) for i in range(10001)]\nnp.mean(medians) \n```", "```py\nnp.float64(3.7121869836715353) \n```", "```py\nmse(means, mu), mse(medians, mu) \n```", "```py\n(np.float64(0.06853430354724438), np.float64(0.031164467796883758)) \n```", "```py\ndef  biased_var(xs):\n    # Compute variance with n in the denominator\n    n = len(xs)\n    deviations = xs - np.mean(xs)\n    return np.sum(deviations**2) / n \n```", "```py\nbiased_vars = [biased_var(make_sample(n=10)) for i in range(10001)]\nnp.mean(biased_vars) \n```", "```py\nnp.float64(0.19049277659404473) \n```", "```py\nactual_var = sigma**2\nactual_var \n```", "```py\n0.2116 \n```", "```py\ndef  unbiased_var(xs):\n    # Compute variance with n-1 in the denominator\n    n = len(xs)\n    deviations = xs - np.mean(xs)\n    return np.sum(deviations**2) / (n - 1) \n```", "```py\nunbiased_vars = [unbiased_var(make_sample(n=10)) for i in range(10001)]\nnp.mean(unbiased_vars) \n```", "```py\nnp.float64(0.21159109492300626) \n```", "```py\nn = 10\n1 - (n - 1) / n \n```", "```py\n0.09999999999999998 \n```", "```py\nn = 100\n1 - (n - 1) / n \n```", "```py\n0.010000000000000009 \n```", "```py\ndownload(\n    \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/c19a904462482430170bfe2c718775ddb7dbb885/inst/extdata/penguins_raw.csv\"\n) \n```", "```py\npenguins = pd.read_csv(\"penguins_raw.csv\").dropna(subset=[\"Body Mass (g)\"])\npenguins.shape \n```", "```py\n(342, 17) \n```", "```py\npenguins[\"Species\"].value_counts() \n```", "```py\nSpecies\nAdelie Penguin (Pygoscelis adeliae)          151\nGentoo penguin (Pygoscelis papua)            123\nChinstrap penguin (Pygoscelis antarctica)     68\nName: count, dtype: int64 \n```", "```py\nchinstrap = penguins.query('Species.str.startswith(\"Chinstrap\")') \n```", "```py\ndef  plot_kde(sample, name=\"estimated density\", **options):\n    kde = gaussian_kde(sample)\n    m, s = np.mean(sample), np.std(sample)\n    plt.axvline(m, color=\"gray\", ls=\":\")\n\n    domain = m - 4 * s, m + 4 * s\n    pdf = Pdf(kde, domain, name)\n    pdf.plot(**options) \n```", "```py\nweights = chinstrap[\"Body Mass (g)\"] / 1000\nplot_kde(weights, \"weights\")\ndecorate(xlabel=\"Penguin weight (kg)\", ylabel=\"Density\") \n```", "```py\nsample_mean = np.mean(weights)\nsample_mean \n```", "```py\nnp.float64(3.733088235294118) \n```", "```py\ndef  resample(sample):\n    # Generate a sample from a normal distribution\n    m, s = np.mean(sample), np.std(sample)\n    return np.random.normal(m, s, len(sample)) \n```", "```py\nsample_means = [np.mean(resample(weights)) for i in range(1001)] \n```", "```py\nplot_kde(sample_means, \"sample means\")\ndecorate(xlabel=\"Sample mean of weight (kg)\", ylabel=\"Density\") \n```", "```py\nstandard_error = np.std(sample_means)\nstandard_error \n```", "```py\nnp.float64(0.04626531069684985) \n```", "```py\nnp.std(weights) \n```", "```py\nnp.float64(0.3814986213564681) \n```", "```py\nnp.std(sample_means) \n```", "```py\nnp.float64(0.04626531069684985) \n```", "```py\ndef  approximate_standard_error(sample):\n    n = len(sample)\n    return np.std(sample) / np.sqrt(n) \n```", "```py\napproximate_standard_error(weights) \n```", "```py\nnp.float64(0.046263503290595163) \n```", "```py\nci90 = np.percentile(sample_means, [5, 95])\nci90 \n```", "```py\narray([3.6576334 , 3.80737506]) \n```", "```py\ndownload(\"https://github.com/AllenDowney/ThinkStats/raw/v3/data/CDBRFS08.ASC.gz\") \n```", "```py\nfrom  thinkstats  import read_brfss\n\nbrfss = read_brfss() \n```", "```py\nmale = brfss.query(\"sex == 1\")\nheights = male[\"htm3\"]\nheights.describe() \n```", "```py\ncount    154407.000000\nmean        178.066221\nstd           7.723563\nmin          61.000000\n25%         173.000000\n50%         178.000000\n75%         183.000000\nmax         236.000000\nName: htm3, dtype: float64 \n```", "```py\nactual_mean = 10 \n```", "```py\ndef  make_exponential(n):\n    return np.random.exponential(actual_mean, size=n) \n```", "```py\nactual_median = np.log(2) * actual_mean\nactual_median \n```", "```py\nnp.float64(6.931471805599453) \n```", "```py\ndef  biased_std(sample):\n    # Square root of the biased estimator of variance\n    var = biased_var(sample)\n    return np.sqrt(var) \n```", "```py\ndef  unbiased_std(sample):\n    # Square root of the unbiased estimator of variance\n    var = unbiased_var(sample)\n    return np.sqrt(var) \n```", "```py\n# Here's an example using `make_sample`\n\nmu, sigma = 3.7, 0.46\nmake_sample(n=10) \n```", "```py\narray([4.5279695 , 3.75698359, 4.09347143, 3.56308034, 3.17123233,\n       4.40734952, 3.70858308, 4.15706704, 4.06716703, 3.7203591 ]) \n```", "```py\ndef  estimate_tanks(sample):\n    m = np.max(sample)\n    k = len(sample)\n    return m + (m - k) / k \n```", "```py\nN = 122\ntanks = np.arange(1, N + 1) \n```", "```py\ndef  sample_tanks(k):\n    return np.random.choice(tanks, replace=False, size=k) \n```", "```py\nnp.random.seed(17) \n```", "```py\nsample = sample_tanks(5)\nsample \n```", "```py\narray([74, 71, 95, 10, 17]) \n```", "```py\nestimate_tanks(sample) \n```", "```py\nnp.float64(113.0) \n```", "```py\ndef  make_hits_and_misses(n):\n    # Generate a random sequence of 0s and 1s\n    return np.random.choice([0, 1], size=n) \n```", "```py\nimport  numpy  as  np\n\ndef  get_successors(seq, target_sum=3):\n  \"\"\"Get the successors of each subsequence that sums to a target value.\n\n Parameters:\n seq (array-like): Sequence of 1s and 0s.\n target_sum (int): The target sum of the subsequence. Default is 3.\n\n Returns:\n np.ndarray: Array of successors to subsequences that sum to `target_sum`.\n \"\"\"\n    # Check if the input sequence is too short\n    if len(seq) < 3:\n        return np.array([])\n\n    # Compute the sum of each subsequence of length 3\n    kernel = [1, 1, 1]\n    corr = np.correlate(seq, kernel, mode=\"valid\")\n\n    # Find the indices where the subsequence sums to the target value\n    indices = np.nonzero(corr == target_sum)[0]\n\n    # Remove cases where the subsequence is at the end of the sequence\n    indices = indices[indices < len(seq) - 3]\n\n    # Find the successors of each valid subsequence\n    successors = seq[indices + 3] if len(indices) > 0 else np.array([])\n\n    return successors \n```"]