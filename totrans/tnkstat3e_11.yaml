- en: Hypothesis Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://allendowney.github.io/ThinkStats/chap09.html](https://allendowney.github.io/ThinkStats/chap09.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the datasets we have explored in this book, we’ve seen differences between
    groups of people – and penguins – correlations between variables, and slopes of
    regression lines. Results like these are called **observed effects** because they
    appear in a sample, as contrasted with actual effects in the population, which
    we usually can’t observe directly. When we see an apparent effect, we should consider
    whether it is likely to be present in the larger population or whether it might
    appear in the sample by chance.
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways to formulate this question, including Fisher null hypothesis
    testing, Neyman-Pearson decision theory, and Bayesian hypothesis testing. What
    I present here is a mixture of these approaches that is often used in practice.
  prefs: []
  type: TYPE_NORMAL
- en: '[Click here to run this notebook on Colab](https://colab.research.google.com/github/AllenDowney/ThinkStats/blob/v3/nb/chap09.ipynb).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Flipping Coins
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ll start with a simple example, based on an example in David MacKay’s book,
    *Information Theory, Inference, and Learning Algorithms*.
  prefs: []
  type: TYPE_NORMAL
- en: When Euro coins were introduced in 2002, a curious coin enthusiast spun a Belgian
    one-Euro coin on edge 250 times and noted that it landed with the heads side up
    140 times and tails side up 110 times. If the coin is perfectly balanced, we expect
    only 125 heads, so this data suggests the coin is biased. On the other hand, we
    don’t expect to get exactly 125 heads every time, so it’s possible that the coin
    is actually fair, and the apparent deviation from the expected value is due to
    chance. To see whether that’s plausible, we can perform a hypothesis test.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use the following function to compute the absolute difference between
    the observed number and the expected number if the coin is fair.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the observed data, this deviation is 15.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: If the coin is actually fair, we can simulate the coin-spinning experiment by
    generating a sequence of random strings – either `'H'` or `'T'` with equal probability
    – and counting the number of times `'H'` appears.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Each time we call this function, we get the outcome of a simulated experiment.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The following loop simulates the experiment many times, computes the deviation
    for each one, and uses a list comprehension to collect the results in a list.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The result is a sample from the distribution of deviations under the assumption
    that the coin is fair. Here’s what the distribution of these values looks like.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/3f731f1367cbe5b239cdb8e7b4f3b4024828e9c8d5c6fca6476b5a0b160761ba.png](../Images/df6cee07f60cfcf7f0c2dac3c53175d2.png)'
  prefs: []
  type: TYPE_IMG
- en: Values near 0 are the most common; values greater than 10 are less common. Remembering
    that the deviation in the observed data is 15, we see that deviations of that
    magnitude are rare, but not impossible. In this example, the simulated results
    equal or exceed 15 about 7.1% of the time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: So, if the coin is fair, we expect a deviation as big as the one we saw about
    7.1% of the time, just by chance.
  prefs: []
  type: TYPE_NORMAL
- en: We can conclude that an effect of this size is not common, but it is certainly
    not impossible, even if the coin is fair. On the basis of this experiment, we
    can’t rule out the possibility that the coin is fair.
  prefs: []
  type: TYPE_NORMAL
- en: This example demonstrates the logic of statistical hypothesis testing.
  prefs: []
  type: TYPE_NORMAL
- en: We started with an observation, 140 heads out of 250 spins, and the hypothesis
    that the coin is biased – that is, that the probability of heads differs from
    50%.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We chose a **test statistic** that quantifies the size of the observed effect.
    In this example, the test statistic is the absolute deviation from the expected
    outcome.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We defined a **null hypothesis**, which is a model based on the assumption that
    the observed effect is due to chance. In this example, the null hypothesis is
    that the coin is fair.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we computed a **p-value**, which is the probability of seeing the observed
    effect if the null hypothesis is true. In this example, the p-value is the probability
    of a deviation as big as 15 or bigger.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last step is to interpret the result. If the p-value is small, we conclude
    that the effect would be unlikely to happen by chance. If it is large, we conclude
    that the effect could plausibly be explained by chance. And if it falls somewhere
    in the middle, as in this example, we can say that the effect is unlikely to happen
    by chance, but we can’t rule out the possibility.
  prefs: []
  type: TYPE_NORMAL
- en: All hypothesis tests are based on these elements – a test statistic, a null
    hypothesis, and a p-value.
  prefs: []
  type: TYPE_NORMAL
- en: '## Testing a Difference in Means'
  prefs: []
  type: TYPE_NORMAL
- en: In the NSFG data, we saw that the average pregnancy length for first babies
    is slightly longer than for other babies. Now let’s see if that difference could
    be due to chance.
  prefs: []
  type: TYPE_NORMAL
- en: The following cells download the data and install `statadict`, which we need
    to read the data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The function `get_nsfg_groups` reads the data, selects live births, and groups
    live births into first babies and others.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Now we can select pregnancy lengths, in weeks, for both groups.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The following function takes the data as a tuple of two sequences, and computes
    the absolute difference in means.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Between first babies and others, the observed difference in pregnancy length
    is 0.078 weeks.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: So the hypothesis we’ll test is whether pregnancy length is generally longer
    for first babies. The null hypothesis is that pregnancy lengths are actually the
    same for both groups, and the apparent difference is due to chance. If pregnancy
    lengths are the same for both groups, we can combine the two groups into a single
    pool. To simulate the experiment, we can use the NumPy function `shuffle` to put
    the pooled values in random order, and then use slice indexes to select two groups
    with the same sizes as the original.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Each time we call this function, it returns a tuple of sequences, which we can
    pass to `abs_diff_means`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The following loop simulates the experiment many times and computes the difference
    in means for each simulated dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: To visualize the results, we’ll use the following function, which takes a sample
    of simulated results and makes a `Pmf` object that approximates its distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We’ll also use this function, which fills in the tail of the distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Here’s what the distribution of the simulated results looks like. The shaded
    region shows the cases where the difference in means under the null hypothesis
    exceeds the observed difference. The area of this region is the p-value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/81d6c7139c0577b81d5868d0444eefc2cb3b4af8c6682b69f0e12ee8b12762f4.png](../Images/5f451e1acdc3326601b708c5225005f2.png)'
  prefs: []
  type: TYPE_IMG
- en: The following function computes the p-value, which is the fraction of simulated
    values that are as big or bigger than the observed value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the p-value is about 18%, which means it is plausible that
    a difference as big as 0.078 weeks could happen by chance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Based on this result, we can’t be sure that pregnancy lengths are generally
    longer for first babies – it’s possible that the difference in this dataset is
    due to chance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that we’ve seen the same elements in both examples of hypothesis testing:
    a test statistic, a null hypothesis, and a model of the null hypothesis. In this
    example, the test statistic is the absolute difference in the means. The null
    hypothesis is that the distribution of pregnancy lengths is actually the same
    in both groups. And we modeled the null hypothesis by combining the data from
    both groups into a single pool, shuffling the pool, and splitting it into two
    groups with the same sizes as the originals. This process is called **permutation**,
    which is another word for shuffling.'
  prefs: []
  type: TYPE_NORMAL
- en: This computational approach to hypothesis testing makes it easy to combine these
    elements to test different statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Other Test Statistics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We might wonder whether pregnancy lengths for first babies are not just longer,
    but maybe more variable. To test that hypothesis, we can use as a test statistic
    the absolute difference between the standard deviations of the two groups. The
    following function computes this test statistic.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: In the NSFG dataset, the difference in standard deviations is about 0.18.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: To see whether this difference might be due to chance, we can use permutation
    again. The following loop simulates the null hypothesis many times and computes
    the difference in standard deviation for each simulated dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Here’s what the distribution of the results looks like. Again, the shaded region
    shows where the test statistic under the null hypothesis exceeds the observed
    difference.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/b8c12d0e47568c186f13da71da99b26caeb16994a333ef5b4b40a75664b5f418.png](../Images/f165cc702fda51a8c6a4274707cfd956.png)'
  prefs: []
  type: TYPE_IMG
- en: We can estimate the area of this region by computing the fraction of results
    that are as big or bigger than the observed difference.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The p-value is about 0.17, so it is plausible that we could see a difference
    this big even if the two groups are the same. In conclusion, we can’t be sure
    that pregnancy lengths are generally more variable for first babies – the difference
    we see in this dataset could be due to chance.
  prefs: []
  type: TYPE_NORMAL
- en: '## Testing a Correlation'
  prefs: []
  type: TYPE_NORMAL
- en: We can use the same framework to test correlations. For example, in the NSFG
    data set, there is a correlation between birth weight and mother’s age – older
    mothers have heavier babies, on average. But could this effect be due to chance?
  prefs: []
  type: TYPE_NORMAL
- en: To find out, we’ll start by preparing the data. From live births, we’ll select
    cases where the age of the mother and birth weight are known.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Then we’ll select the relevant columns.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The following function takes a tuple of `xs` and `ys` and computes the magnitude
    of the correlation, positive or negative.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: In the NSFG dataset, the correlation is about 0.07.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: The null hypothesis is that there is no correlation between mother’s age and
    birth weight. By shuffling the observed values, we can simulate a world where
    the distributions of age and birth weight are the same, but where the variables
    are unrelated.
  prefs: []
  type: TYPE_NORMAL
- en: The following function takes a tuple of `xs` and `ys`, shuffles `xs` and returns
    a tuple containing the shuffled `xs` and the original `ys`. It would also work
    if we shuffled the `ys` instead, or shuffled both.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The correlation of the shuffled values is usually close to 0.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The following loop generates many shuffled datasets and computes the correlation
    of each one.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Here’s what the distribution of the results looks like. The vertical dotted
    line shows the observed correlation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/13f0b2847c5affed82786df164109c3381eaca6f5bb8a72c941468da3a31b613.png](../Images/db72472b65ca6709d8abdf0c5824445e.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see that the observed correlation is in the tail of the distribution,
    with no visible area under the curve. If we try to compute a p-value, the result
    is 0, indicating that the correlation in the shuffled data did not exceed the
    observed value in any of the simulations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Based on this calculation, we can conclude that the p-value is probably less
    that 1 per 1000, but it is not actually zero. It is unlikely for the correlation
    of the shuffled data to exceed the observed value – but it is not impossible.
  prefs: []
  type: TYPE_NORMAL
- en: When the p-value is small, traditionally less than 0.05, we can say that the
    result is **statistically significant**. But this way of interpreting p-values
    has always been problematic, and it is slowly becoming less widely used.
  prefs: []
  type: TYPE_NORMAL
- en: One problem is that the traditional threshold is arbitrary and not appropriate
    for all applications. Another problem is that this use of “significant” is misleading
    because it suggests that the effect is important in practice. The correlation
    between mother’s age and birth weight is a good example – it is statistically
    significant, but so small that it is not important.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative is to interpret p-values qualitatively.
  prefs: []
  type: TYPE_NORMAL
- en: If a p-value is large, it is plausible that the observed effect could happen
    by chance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If the p-value is small, we can often rule out the possibility that the effect
    is due to chance – but we should remember that it could still be due to non-representative
    sampling or measurement errors.  ## Testing Proportions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a final example, let’s consider a case where the choice of the test statistic
    takes some thought. Suppose you run a casino and you suspect that a customer is
    using a crooked die – that is, one that has been modified to make one of the faces
    more likely than the others. You apprehend the alleged cheater and confiscate
    the die, but now you have to prove that it is crooked. You roll the die 60 times
    and record the frequency of each outcome from 1 to 6. Here are the results in
    a `Hist` object.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '|  | freqs |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| outcome |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 9 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 19 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 11 |'
  prefs: []
  type: TYPE_TB
- en: On average you expect each value to appear 10 times. In this dataset, the value
    3 appears more often than expected, and the value 4 appears less often. But could
    these differences happen by chance?
  prefs: []
  type: TYPE_NORMAL
- en: To test this hypothesis, we’ll start by computing the expected frequency for
    each outcome.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The following function takes the observed and expected frequencies and computes
    the sum of the absolute differences.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: In the observed dataset, this test statistic is 20.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: The following function takes the observed data, simulates rolling a fair die
    the same number of times, and returns a `Hist` object that contains the simulated
    frequencies.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The following loop simulates the experiment many times and computes the total
    absolute deviation for each one.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Here’s what the distribution of the test statistic looks like under the null
    hypothesis. Notice that the total is always even, because every time an outcome
    appears more often than expected, another outcome has to appear less often.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/5d7743f38a1eac8ca1cf10492e5cf1c48871dc6438957ffc7779e99c151dc2a7.png](../Images/f35961f248e3137b8311191357531d0c.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see that a total deviation of 20 is not unusual – the p-value is about
    13%, which means that we can’t be sure the die is crooked.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: But the test statistic we chose was not the only option. For a problem like
    this, it would be more conventional to use the chi-squared statistic, which we
    can compute like this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Squaring the deviations (rather than taking absolute values) gives more weight
    to large deviations. Dividing through by `expected` standardizes the deviations
    – although in this case it has no effect on the results because the expected frequencies
    are all equal.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: The chi-squared statistic of the observed data is 11.6. By itself, this number
    doesn’t mean very much, but we can compare it to the results from the simulated
    rolls. The following loop generates many simulated datasets and computes the chi-squared
    statistic for each one.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Here’s what the distribution of this test statistic looks like under the null
    hypothesis. The shaded region shows the results that exceed the observed value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '![_images/0926b356306842c735f4b20897a267d1115265c91109c553776b3382d5b099c6.png](../Images/0b28b7eb8065f72d9b5314eb0beb20f2.png)'
  prefs: []
  type: TYPE_IMG
- en: Again, the area of the shaded region is the p-value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: The p-value using the chi-squared statistic is about 0.04, substantially smaller
    than what we got using total deviation, 0.13. If we take the 5% threshold seriously,
    we would consider this effect statistically significant. But considering the two
    tests together, I would say that the results are inconclusive. I would not rule
    out the possibility that the die is crooked, but I would not convict the accused
    cheater.
  prefs: []
  type: TYPE_NORMAL
- en: 'This example demonstrates an important point: the p-value depends on the choice
    of test statistic and the model of the null hypothesis, and sometimes these choices
    determine whether an effect is statistically significant or not.'
  prefs: []
  type: TYPE_NORMAL
- en: Glossary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**hypothesis testing**: A set of methods for checking whether an observed effect
    could plausibly be due to random sampling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**test statistic**: A statistic used in a hypothesis test to quantify the size
    of an observed effect.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**null hypothesis**: A model of a system based on the assumption that an effect
    observed in a sample does not exist in the population.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**permutation**: A way to simulate a null hypothesis by randomly shuffling
    a dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**p-value**: The probability of an effect as big as the observed effect, under
    a null hypothesis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**statistically significant**: An effect is statistically significant if the
    p-value is smaller than a chosen threshold, often 5%. In a large dataset, an observed
    effect can be statistically significant even if it is too small to matter in practice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Exercise 9.1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s try hypothesis testing with the penguin data from [Chapter 8](chap08.html#section-sampling-distributions).
    Instructions for downloading the data are in the notebook for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The following cell downloads the data from a repository created by Allison Horst.
  prefs: []
  type: TYPE_NORMAL
- en: 'Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica)
    penguin data. R package version 0.1.0\. [https://allisonhorst.github.io/palmerpenguins/](https://allisonhorst.github.io/palmerpenguins/).
    doi: 10.5281/zenodo.3960218.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The data was collected as part of the research that led to this paper: Gorman
    KB, Williams TD, Fraser WR (2014). Ecological sexual dimorphism and environmental
    variability within a community of Antarctic penguins (genus Pygoscelis). PLoS
    ONE 9(3):e90081\. [https://doi.org/10.1371/journal.pone.0090081](https://doi.org/10.1371/journal.pone.0090081)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Here’s how we read the data and select the Chinstrap penguins.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: And here’s how we can extract the weights for male and female penguins in kilograms.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Use `abs_diff_means` and `simulate_groups` to generate a large number of simulated
    datasets under the null hypothesis that the two groups have the same distribution
    of weights, and compute the difference in means for each one. Compare the simulation
    results to the observed difference and compute a p-value. Is it plausible that
    the apparent difference between the groups is due to chance?
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 9.2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using the penguin data from the previous exercise, we can extract the culmen
    depths and lengths for the female penguins (the culmen is the top ridge of the
    bill).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: The correlation between these variables is about 0.26.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: Let’s see whether this correlation could happen by chance, even if there is
    actually no correlation between the measurements. Use `permute` to generate many
    permutations of this data and `abs_correlation` to compute the correlation for
    each one. Plot the distribution of the correlations under the null hypothesis
    and compute a p-value for the observed correlation. How do you interpret the result?
  prefs: []
  type: TYPE_NORMAL
- en: '[Think Stats: Exploratory Data Analysis in Python, 3rd Edition](https://allendowney.github.io/ThinkStats/index.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Copyright 2024 [Allen B. Downey](https://allendowney.com)
  prefs: []
  type: TYPE_NORMAL
- en: 'Code license: [MIT License](https://mit-license.org/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Text license: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/)'
  prefs: []
  type: TYPE_NORMAL
